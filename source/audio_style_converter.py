import os
from pydub import AudioSegment
import math
from openai import OpenAI
import tempfile
import re
import unicodedata
import configparser
import argparse
import json

class TranslationStyle:
    PODCAST = "podcast"
    SUNDAY_JAPON = "sunday_japon"
    NEWS_REPORT = "news_report"

    @staticmethod
    def get_prompt(style):
        print(f"Input style: {style}")  # ãƒ‡ãƒãƒƒã‚°ç”¨

        prompts = {
            "podcast": """ã‚ãªãŸã¯ã€è‹±èªã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é­…åŠ›çš„ãªæ—¥æœ¬èªã®ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆå½¢å¼ã«å¤‰æ›ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®è¦ç´ ã‚’çµ„ã¿è¾¼ã‚“ã§ã€è‡ªç„¶ã§é­…åŠ›çš„ãªå¯¾è©±ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

1. ä¼šè©±ã®æ§‹é€ ã¨ãƒ•ãƒ­ãƒ¼
- ãƒ›ã‚¹ãƒˆã¨ã‚²ã‚¹ãƒˆã®è‡ªç„¶ãªå¯¾è©±ã‚’ä½œæˆ
- è©±é¡Œã®å°å…¥ã€å±•é–‹ã€ã¾ã¨ã‚ã®æµã‚Œã‚’æ„è­˜
- é©åˆ‡ãªç›¸ã¥ã¡ï¼ˆã€Œãªã‚‹ã»ã©ã€ã€Œãã†ã§ã™ã­ã€ï¼‰ã‚„é–“æŠ•è©ï¼ˆã€Œãˆãƒ¼ã¨ã€ã€Œã‚ã®ã€ï¼‰ã‚’æ´»ç”¨
- ä¼šè©±ã®é€”ä¸­ã§ç›¸æ‰‹ã®ç™ºè¨€ã«é–¢é€£ã¥ã‘ãŸè³ªå•ã‚„æ„è¦‹ã‚’æŒŸã‚€

2. è©±ã—è¨€è‘‰ã¨ã—ã¦ã®ç‰¹å¾´
- ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã§ã‚ã‚ŠãªãŒã‚‰å“ä½ã®ã‚ã‚‹ä¼šè©±è¡¨ç¾ã‚’ä½¿ç”¨
- æ–‡è„ˆã«å¿œã˜ã¦é©åˆ‡ãªæ•¬èªãƒ¬ãƒ™ãƒ«ã‚’é¸æŠ
- å£°ã«å‡ºã—ãŸæ™‚ã®è‡ªç„¶ãªãƒªã‚ºãƒ æ„Ÿã‚’é‡è¦–""",

            "sunday_japon": """ã‚ãªãŸã¯ã€è‹±èªã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’çˆ†ç¬‘å•é¡Œã®å¸ä¼šã™ã‚‹ã‚µãƒ³ãƒ‡ãƒ¼ã‚¸ãƒ£ãƒãƒ³ã•ãªãŒã‚‰ã®
è¨è«–ãƒãƒ©ã‚¨ãƒ†ã‚£ç•ªçµ„å½¢å¼ã«å¤‰æ›ã™ã‚‹ã‚¹ãƒšã‚·ãƒ£ãƒªã‚¹ãƒˆã§ã™ã€‚
ä»¥ä¸‹ã®è¦ç´ ã‚’ãµã‚“ã ã‚“ã«ç››ã‚Šè¾¼ã¿ã€å¤ªç”°å…‰é¢¨ã®æ¯’èˆŒï¼†é‹­ã„åˆ†æã¨ã€ç”°ä¸­è£•äºŒé¢¨ã®åº¶æ°‘ç›®ç·šã®ãƒ„ãƒƒã‚³ãƒŸãŒ
çµ¶å¦™ã«äº¤å·®ã™ã‚‹ã€ãƒ†ãƒ³ãƒã®è‰¯ã„ç¬‘ã„ã¨è­°è«–ã‚’ä½œã‚Šä¸Šã’ã¦ãã ã•ã„ï¼

1. è¨è«–ãƒ»ãƒˆãƒ¼ã‚¯ã®ç‰¹å¾´
- å¤ªç”°å…‰ã°ã‚Šã®æ¯’èˆŒã‚„æ™‚äº‹å•é¡Œã¸ã®ã‚ºãƒãƒƒã¨ã—ãŸåˆ‡ã‚Šè¾¼ã¿
- ç”°ä¸­è£•äºŒã«ã‚ˆã‚‹â€œãˆãƒ¼ã€ãã‚Œã¯å¤‰ã§ã—ã‚‡ã†ï¼â€ãªã©ã®ã‚ã‹ã‚Šã‚„ã™ã„ãƒ„ãƒƒã‚³ãƒŸ
- ãƒ‘ãƒãƒªã‚¹ãƒˆï¼ˆå‡ºæ¼”è€…ï¼‰ã‚‚ç™»å ´ã—ã€äºˆæƒ³å¤–ã®ãƒœã‚±ã‚„è«–ç‚¹ãšã‚‰ã—ã«å¯¾ã—ã¦é‹­ãåˆ‡ã‚Šè¿”ã—
- ãƒ¯ã‚¤ãƒ‰ã‚·ãƒ§ãƒ¼çš„ã«æ‰±ã†æ™‚äº‹ãƒã‚¿ã‚„ãƒãƒƒãƒ—ã‚«ãƒ«ãƒãƒ£ãƒ¼ã‚’é æ…®ãªãæŠ•å…¥
- æ€¥ã«è¦–ç‚¹ã‚’åˆ‡ã‚Šæ›¿ãˆã¦ã€Œã¾ã˜ã‚ã«è€ƒãˆã¾ã—ã‚‡ã†ã‚ˆï¼ã€ãªã©ã€ç¬‘ã„ã‹ã‚‰çœŸé¢ç›®ãƒ¢ãƒ¼ãƒ‰ã¸ã®ç´ æ—©ã„è»¢æ›

2. è©±ã—æ–¹ãƒ»æ›ã‘åˆã„ã®ç‰¹å¾´
- ãƒ„ãƒƒã‚³ãƒŸãƒ•ãƒ¬ãƒ¼ã‚ºã‚„ã€Œã¡ã‚‡ã£ã¨å¾…ã£ã¦ã‚ˆï¼ã€ã€Œãã‚Œãƒ¤ãƒããªã„ï¼ï¼Ÿã€ã€Œã„ã‚„ã€æ„å‘³ã‚ã‹ã‚“ãªã„ï¼ã€ãªã©ã€
  ãƒãƒ©ã‚¨ãƒ†ã‚£ç‰¹æœ‰ã®å‹¢ã„ã®ã‚ã‚‹è¨€ã„å›ã—ã‚’å¤šç”¨
- ç”°ä¸­é¢¨ã®ã€Œã„ã‚„ã„ã‚„ã€ãã‚“ãªã‚ã‘ãªã„ã§ã—ã‚‡ï¼Ÿã€ã¨ã„ã£ãŸâ€œåº¶æ°‘ç›®ç·šâ€ã§ã®ç›¸æ§Œã‚„è‹¦ç¬‘ã„
- å¤ªç”°é¢¨ã®ã‚·ãƒ‹ã‚«ãƒ«ãƒ»çš®è‚‰æ··ã˜ã‚Šã®ã‚³ãƒ¡ãƒ³ãƒˆã§ç¬‘ã„ã‚’èª˜ã†
- é©åº¦ãªã‚ªãƒ¼ãƒãƒ¼ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€å¤§ã’ã•ãªè¡¨ç¾ã§å ´ã‚’ç››ã‚Šä¸Šã’ã‚‹
- ã€Œã‚¹ãƒãƒ³ã‚µãƒ¼å¤§ä¸ˆå¤«ã‹ãªï¼Ÿã€ãªã©ã®ç•ªçµ„é¢¨è‡ªè™ãƒã‚¿ã‚‚OK

3. æ¼”å‡ºãƒ»ç•ªçµ„ã®é›°å›²æ°—
- çˆ†ç¬‘å•é¡Œç‰¹æœ‰ã®æ›ã‘åˆã„ãŒç•ªçµ„ã®ä¸»è»¸ã€‚å¤ªç”°ãŒãƒœã‚±ã‚„æŒ‘ç™ºçš„ãªã‚³ãƒ¡ãƒ³ãƒˆã€ç”°ä¸­ãŒè½ã¡ç€ã„ãŸãƒˆãƒ¼ãƒ³ã§ã®ãƒ„ãƒƒã‚³ãƒŸ
- ã€Œã¿ãªã•ã‚“ã€ã©ã†ã§ã™ã‹ï¼Ÿã€ã¨ãƒ‘ãƒãƒªã‚¹ãƒˆã«è©±ã‚’æŒ¯ã‚Šã€æ™‚ã«ã‚·ãƒ§ãƒƒã‚­ãƒ³ã‚°ãªæ„è¦‹ã‚„èŒ¶ã€…ã‚’å…¥ã‚Œã¦çˆ†ç¬‘ã‚’èª˜ã†
- å¤§ã’ã•ãªé©šãåŠ¹æœéŸ³ã‚’æƒ³èµ·ã•ã›ã‚‹ã‚ˆã†ãªè¨€è‘‰ï¼ˆã€Œãˆãˆãƒ¼ã£ï¼ï¼Ÿã€ã€Œã‚¦ã‚½ã§ã—ã‚‡ï¼ã€ãªã©ï¼‰ã‚’è¦æ‰€ã§æŒ¿å…¥
- çœŸé¢ç›®ãªè©±é¡Œã‚„ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šä¸Šã’ã¤ã¤ã‚‚ã€ç¬‘ã„ã‚’çµ¶ã‚„ã•ãªã„ãƒãƒ©ã‚¨ãƒ†ã‚£æ„Ÿ
- â€œèŠ¸èƒ½ãƒã‚¿â€ã‚„â€œãƒãƒƒãƒˆã§ãƒã‚ºã£ã¦ã„ã‚‹è©±é¡Œâ€ã‚’æ™‚ã€…æŒŸã¿ã¤ã¤ã€æ™‚äº‹ãƒ»æ”¿æ²»ãƒã‚¿ã‚‚ã—ã£ã‹ã‚Šè«–ã˜ã‚‹
""",
            "news_report": """ã‚ãªãŸã¯ã€è‹±èªã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä¿¡é ¼æ€§ã®é«˜ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒªãƒãƒ¼ãƒˆå½¢å¼ã«å¤‰æ›ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®è¦ç´ ã‚’çµ„ã¿è¾¼ã‚“ã§ã€æ­£ç¢ºã§åˆ†ã‹ã‚Šã‚„ã™ã„å ±é“ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

1. å ±é“ã®ç‰¹å¾´
- å®¢è¦³çš„ã§æ­£ç¢ºãªäº‹å®Ÿä¼é”
- ç°¡æ½”æ˜ç­ãªè¡¨ç¾
- ä¿¡é ¼æ„Ÿã®ã‚ã‚‹ãƒˆãƒ¼ãƒ³
- é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã®å¼·èª¿

2. è©±ã—æ–¹ã®ç‰¹å¾´
- ãƒ•ã‚©ãƒ¼ãƒãƒ«ã§ä¸å¯§ãªè¨€è‘‰é£ã„
- æ˜ç­ãªç™ºéŸ³ã¨é©åˆ‡ãªé–“ã®å–ã‚Šæ–¹
- ä¸­ç«‹çš„ãªç«‹å ´ã‹ã‚‰ã®è§£èª¬
- å°‚é–€ç”¨èªã®åˆ†ã‹ã‚Šã‚„ã™ã„èª¬æ˜"""
        }

        common_requirements = """

å¿…é ˆæ¡ä»¶ï¼š
- å„ç™ºè¨€ã®å‰ã«[è©±è€…A]ã¾ãŸã¯[è©±è€…B]ã®ã¿ã‚’æ˜ç¤ºçš„ã«ä»˜ä¸
- åŒã˜è©±è€…ã«ã¯ä¸€è²«ã—ã¦åŒã˜ãƒ©ãƒ™ãƒ«ã‚’ä½¿ç”¨
- [è©±è€…A]ã‚’ãƒ¡ã‚¤ãƒ³è©±è€…ã€[è©±è€…B]ã‚’ã‚µãƒ–è©±è€…ã¨ã—ã¦è¨­å®š(ã“ã®ï¼’åä»¥å¤–ã®è©±è€…ã®åˆ©ç”¨ã¯ç¦æ­¢)
- éŸ³å£°å¤‰æ›æ™‚ã®å“è³ªã‚’è€ƒæ…®ã—ã€èª­ç‚¹ã®ä½ç½®ã‚„æ–‡ã®é•·ã•ã«æ³¨æ„

ä¸Šè¨˜ã®ã™ã¹ã¦ã‚’è¸ã¾ãˆã¤ã¤ã€ä»¥ä¸‹ã®è‹±èªãƒ†ã‚­ã‚¹ãƒˆã‚’ä»•ç«‹ã¦ç›´ã—ã¦ãã ã•ã„ã€‚
"""
        if style not in prompts:
            print(f"Warning: Invalid style '{style}' specified, using default podcast style")
            style = "podcast"

        selected_prompt = prompts[style]
        print(f"Selected prompt: {selected_prompt[:100]}...")  # ãƒ‡ãƒãƒƒã‚°ç”¨
        return selected_prompt + common_requirements

class AudioTranslator:
    def __init__(self, config_path='config.ini'):
        # Load configuration
        config = configparser.ConfigParser()
        config.read(config_path)
        
        # Get OpenAI settings
        self.openai_api_key = config['OpenAI']['api_key']
        self.transcription_model = config['Models']['transcription_model']
        self.translation_model = config['Models']['translation_model']
        self.tts_model = config['Models']['tts_model']
        self.html_generation_model = config['Models']['html_generation_model']
        
        # Get translation style
        self.translation_style = config.get('Translation', 'style', 
                                          fallback="podcast")
        print(f"Loaded style from config: {self.translation_style}")  # ãƒ‡ãƒãƒƒã‚°è¿½åŠ 

        self.client = OpenAI(api_key=self.openai_api_key)
        self.MAX_FILE_SIZE = 24 * 1024 * 1024

    # ä»¥ä¸‹ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯å¤‰æ›´ãªã—
    def split_audio(self, audio_path):
        """Split audio file into chunks smaller than 25MB"""
        audio = AudioSegment.from_wav(audio_path)
        duration_ms = len(audio)
        
        file_size = os.path.getsize(audio_path)
        chunk_count = math.ceil(file_size / self.MAX_FILE_SIZE)
        chunk_duration = duration_ms // chunk_count

        chunks = []
        for i in range(chunk_count):
            start_time = i * chunk_duration
            end_time = (i + 1) * chunk_duration if i < chunk_count - 1 else duration_ms
            
            chunk = audio[start_time:end_time]
            chunk_path = f"temp_chunk_{i}.wav"
            chunk.export(chunk_path, format="wav")
            chunks.append(chunk_path)
        
        return chunks

    def transcribe_audio(self, audio_path):
        """Convert audio to English text using OpenAI Whisper API"""
        if os.path.getsize(audio_path) > self.MAX_FILE_SIZE:
            print("File too large, splitting into chunks...")
            chunks = self.split_audio(audio_path)
            transcripts = []
            
            for chunk_path in chunks:
                with open(chunk_path, "rb") as audio_file:
                    transcript = self.client.audio.transcriptions.create(
                        model=self.transcription_model,
                        file=audio_file
                    )
                transcripts.append(transcript.text)
                os.remove(chunk_path)  # Clean up chunk file
            
            return " ".join(transcripts)
        else:
            with open(audio_path, "rb") as audio_file:
                transcript = self.client.audio.transcriptions.create(
                    model=self.transcription_model,
                    file=audio_file
                )
            return transcript.text

    def normalize_japanese_text(self, text):
        """ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–ï¼šå…¨è§’åŠè§’ã®çµ±ä¸€ã€ä¸è¦ãªç©ºç™½ã®å‰Šé™¤ã€è¨˜å·ã®æ•´å½¢ãªã©"""
        normalized = unicodedata.normalize("NFKC", text)
        normalized = re.sub(r'\s+', ' ', normalized)
        normalized = normalized.strip()
        return normalized

    def translate_to_japanese(self, english_text):
        """Translate English text to Japanese using GPT-4 with specified style"""
        translation_prompt = TranslationStyle.get_prompt(self.translation_style)
        print(f"Using style: {self.translation_style}")  # ãƒ‡ãƒãƒƒã‚°è¿½åŠ 

        response = self.client.chat.completions.create(
            model=self.translation_model,
            messages=[
                {"role": "user", "content": translation_prompt + english_text}
            ]
        )
        japanese_text = response.choices[0].message.content
        return self.normalize_japanese_text(japanese_text)

    def split_by_speaker(self, japanese_text):
        """Split text into segments by speaker"""
        segments = []
        pattern = r'(\[è©±è€…[AB]\])([^\\[]+?)(?=(\[è©±è€…[AB]\]|$))'
        matches = re.findall(pattern, japanese_text, re.DOTALL)
        
        for match in matches:
            speaker_label = match[0]
            text = match[1].strip()
            speaker = re.sub(r'\W', '', speaker_label)
            segments.append({
                'speaker': speaker[-1],
                'text': text
            })
        return segments

    def generate_japanese_audio(self, japanese_text, output_path):
        """Generate Japanese speech using OpenAI TTS API"""
        segments = self.split_by_speaker(japanese_text)
        combined_audio = None
        temp_files = []

        try:
            for segment in segments:
                with tempfile.NamedTemporaryFile(suffix=".mp3", delete=False) as temp_file:
                    response = self.client.audio.speech.create(
                        model=self.tts_model,
                        voice="nova" if segment['speaker'] == 'A' else "shimmer",
                        input=segment['text']
                    )
                    temp_file.write(response.content)
                    temp_files.append(temp_file.name)

                    segment_audio = AudioSegment.from_mp3(temp_file.name)
                    if combined_audio is None:
                        combined_audio = segment_audio
                    else:
                        combined_audio += segment_audio

            # Create output directory if it doesn't exist
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            combined_audio.export(output_path, format="mp3")

        finally:
            # Clean up temporary files
            for temp_file in temp_files:
                try:
                    os.remove(temp_file)
                except:
                    pass

    def generate_html(self, japanese_text, output_path):
        """Generate HTML file from Japanese transcript using the template"""
        # Read the template file
        template_path = os.path.join(os.path.dirname(__file__), "templates", "templates.html")
        with open(template_path, 'r', encoding='utf-8') as f:
            template_content = f.read()

        # Create prompt for GPT to generate HTML
        prompt = f"""ä»¥ä¸‹ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆHTMLã¨ä¼šè©±æ–‡ã‹ã‚‰ã€HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆHTML:
{template_content}

ä¼šè©±æ–‡:
{japanese_text}

è¦ä»¶ï¼š
1. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®æ§‹é€ ã¨ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ç¶­æŒã—ãªãŒã‚‰ã€ä»¥ä¸‹ã®éƒ¨åˆ†ã‚’ä¼šè©±å†…å®¹ã«åŸºã¥ã„ã¦æœ€é©åŒ–ã—ã¦ãã ã•ã„ï¼š

   a) ãƒ˜ãƒƒãƒ€ãƒ¼éƒ¨åˆ†ï¼š
      - ã‚¿ã‚¤ãƒˆãƒ«ï¼šä¼šè©±å†…å®¹ã‚’ç«¯çš„ã«è¡¨ã™é©åˆ‡ãªã‚¿ã‚¤ãƒˆãƒ«ã¨ã€å†…å®¹ã«åˆã£ãŸçµµæ–‡å­—ã‚’è¨­å®š
      - ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã®ç¨®é¡ï¼š
        - ä¼šè©±ã®å½¢å¼ã‚’å…·ä½“çš„ã«åˆ†æï¼ˆä¾‹ï¼šã€Œæ”¿ç­–åˆ†æãƒ‹ãƒ¥ãƒ¼ã‚¹ã€ã€ŒçµŒæ¸ˆãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬ã€ã€Œãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ãƒˆãƒ¼ã‚¯ã€ãªã©ï¼‰
        - ã€ŒğŸ§ xxxxãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã€ã®éƒ¨åˆ†ã‚’ã€ŒğŸ§ [å…·ä½“çš„ãªãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆå]ã€ã«ç½®æ›
      - å‡ºæ¼”è€…ï¼š
        - ã€ŒğŸ‘¥ è©±è€…A & è©±è€…Bã€ã¨ã„ã†å½¢å¼ã§ã¯ãªã
        - ã€ŒğŸ‘¥ è©±è€…A(æ”¿ç­–ã‚¢ãƒŠãƒªã‚¹ãƒˆ) & è©±è€…B(çµŒæ¸ˆè©•è«–å®¶)ã€ã®ã‚ˆã†ã«
        - å„è©±è€…ã®å…·ä½“çš„ãªå½¹å‰²ã‚„è‚©æ›¸ãã‚’ä¼šè©±å†…å®¹ã‹ã‚‰åˆ†æã—ã¦è¨˜è¼‰
      - ãƒˆãƒ”ãƒƒã‚¯ï¼š
        - ä¼šè©±ã®ä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã‚’å…·ä½“çš„ã«æŠ½å‡º
        - å„ãƒˆãƒ”ãƒƒã‚¯ã«æœ€é©ãªçµµæ–‡å­—ã‚’ä»˜ä¸

   b) ä¼šè©±éƒ¨åˆ†ï¼š
      - [è©±è€…A]ã®ç™ºè¨€ â†’ message-aã‚¯ãƒ©ã‚¹ã§å·¦å´ã«é…ç½®
      - [è©±è€…B]ã®ç™ºè¨€ â†’ message-bã‚¯ãƒ©ã‚¹ã§å³å´ã«é…ç½®
      - è©±è€…Aã®ã‚¢ã‚¤ã‚³ãƒ³ â†’ fa-user
      - è©±è€…Bã®ã‚¢ã‚¤ã‚³ãƒ³ â†’ fa-robot
      - speaker-roleã‚¯ãƒ©ã‚¹ â†’ åˆ†æã—ãŸå…·ä½“çš„ãªå½¹å‰²ã‚’è¨­å®šï¼ˆä¾‹ï¼šã€Œæ”¿ç­–ã‚¢ãƒŠãƒªã‚¹ãƒˆã€ã€ŒçµŒæ¸ˆè©•è«–å®¶ã€ï¼‰

2. å‡ºåŠ›å½¢å¼ï¼š
   - HTMLã‚³ãƒ¼ãƒ‰ã®ã¿ã‚’å‡ºåŠ›ï¼ˆèª¬æ˜æ–‡ã¯ä¸è¦ï¼‰
   - ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ã‚¹ã‚¿ã‚¤ãƒ«ã¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ãã®ã¾ã¾ç¶­æŒ

é‡è¦ãªæ³¨æ„ç‚¹ï¼š
- ã€Œxxxxã€ã®ã‚ˆã†ãªä»®ã®æ–‡å­—åˆ—ã¯ä½¿ç”¨ã›ãšã€å¿…ãšä¼šè©±å†…å®¹ã‹ã‚‰å…·ä½“çš„ãªæƒ…å ±ã‚’æŠ½å‡ºã—ã¦ç½®æ›ã—ã¦ãã ã•ã„
- è©±è€…ã®å½¹å‰²ã¯ä¼šè©±ã®æ–‡è„ˆã‹ã‚‰å…·ä½“çš„ã«æ¨æ¸¬ã—ã€ä¸€èˆ¬çš„ãªã€Œãƒ›ã‚¹ãƒˆã€ã€Œã‚²ã‚¹ãƒˆã€ã§ã¯ãªãã€å°‚é–€æ€§ã‚„ç«‹å ´ãŒåˆ†ã‹ã‚‹è¡¨ç¾ã«ã—ã¦ãã ã•ã„
- ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆã®ç¨®é¡ã‚‚å…·ä½“çš„ãªã‚‚ã®ã«ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€Œãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬ã€ã§ã¯ãªãã€Œå›½éš›æ”¿æ²»ãƒ‹ãƒ¥ãƒ¼ã‚¹è§£èª¬ã€ãªã©ï¼‰

ä¼šè©±å†…å®¹ã‚’è©³ç´°ã«åˆ†æã—ã€å…·ä½“çš„ã§é©åˆ‡ãªæƒ…å ±ã‚’HTMLã«çµ„ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚"""

        response = self.client.chat.completions.create(
            model=self.html_generation_model,
            messages=[
                {"role": "user", "content": prompt}
            ]
        )
        
        html_content = response.choices[0].message.content.strip()
        
        # HTMLã‚¿ã‚°ã®å‰å¾Œã®èª¬æ˜æ–‡ã‚’å‰Šé™¤
        html_content = re.sub(r'^.*?<!DOCTYPE', '<!DOCTYPE', html_content, flags=re.DOTALL)
        html_content = re.sub(r'</html>.*$', '</html>', html_content, flags=re.DOTALL)

        # Create output directory if it doesn't exist
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # Save the generated HTML
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html_content)

    def generate_output_filename(self, input_filename):
        """Generate output filenames for mp3 and html files"""
        base_name = os.path.splitext(os.path.basename(input_filename))[0]
        output_dir = os.path.join(os.path.dirname(__file__), "output")
        return (
            os.path.join(output_dir, f"{base_name}.mp3"),
            os.path.join(output_dir, f"{base_name}.html")
        )

def main():
    parser = argparse.ArgumentParser(description='è‹±èªéŸ³å£°ã‚’æ—¥æœ¬èªéŸ³å£°ã«å¤‰æ›ã™ã‚‹ãƒ„ãƒ¼ãƒ«')
    parser.add_argument('input_file', help='å…¥åŠ›éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆMP3å½¢å¼ï¼‰')
    args = parser.parse_args()

    translator = AudioTranslator()
    
    # Convert mp3 to wav for processing
    input_wav = "temp_input.wav"
    audio = AudioSegment.from_mp3(args.input_file)
    audio.export(input_wav, format="wav")

    try:
        # Generate output filenames
        output_mp3, output_html = translator.generate_output_filename(args.input_file)

        # Process the audio
        print("éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...")
        english_text = translator.transcribe_audio(input_wav)
        
        print("æ—¥æœ¬èªã«ç¿»è¨³ä¸­...")
        japanese_text = translator.translate_to_japanese(english_text)
        print("=japanese_text=",japanese_text)
        print("æ—¥æœ¬èªéŸ³å£°ã‚’ç”Ÿæˆä¸­...")
        translator.generate_japanese_audio(japanese_text, output_mp3)
        
        print("HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆä¸­...")
        translator.generate_html(japanese_text, output_html)
        
        print(f"å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
        print(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {output_mp3}")
        print(f"HTMLãƒ•ã‚¡ã‚¤ãƒ«: {output_html}")

    finally:
        # Clean up temporary wav file
        if os.path.exists(input_wav):
            os.remove(input_wav)

if __name__ == "__main__":
    main()